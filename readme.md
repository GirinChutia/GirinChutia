### Hi, I'm Girin üëã


- üî≠ I‚Äôm currently working on Computer Vision models from Automatic Defect Recognitions (ADR).
- üì´ How to reach me: girin.iitm@gmail.com

## Achievement & Recognitions 
### [BMW SORDI.ai Hackathon 2022 - 6'th Position](https://sordi.ai/hackathon)

Out of a pool of over 2100 data scientists competing for over four months in the largest industrial AI data science competition in the world, I achieved an **Global Rank 6** in the BMW SORDI.ai Hackathon 2022. This intense and prestigious competition was organized by some of the biggest names in tech, including Microsoft, NVIDIA, BMW Group + QUT Design Academy, idealworks, and the BMW Group. It was an incredible experience to showcase my skills and compete at such a high level.

### [Summer Challenge on Writer Verification, National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics 2023 (NCVPRIPG'23) - 2nd Position](https://vl2g.github.io/challenges/wv2023/)

The Writer Verification task began as a way to detect potential fraud in the banking sector by verifying signatures. This task is difficult because people's handwriting can vary significantly, making it necessary for the model to learn these variations. The task becomes even more complex in offline settings, where dynamic information about the writing process is not available, such as when writing on electronic equipment. 
The task of the challenge was to given a pair of handwritten text images, automatically determine whether they are written by the same writer or different writers.

[Solution Codebase](https://github.com/GirinChutia/NCVPRIPG2023_SummerChallengeOnWriterVerification_TeamInkSq)

## Computer Vision Projects 

### [SAM-ONNX](https://github.com/GirinChutia/SAM_ONNX/) ü•≠

A pip package designed to seamlessly integrate and leverage the potent capabilities of the SAM (Segment Anything Model), requiring only the most minimal dependencies.

### [Indian Currency Recognition using AI](https://github.com/GirinChutia/IndCurr) üí´ 

This is a project where I use a CNN that can recognize the currency of different denominations. I have also implemented a Streamlit app for easy inference of the trained model. Some practical use cases of the model include:

1. Currency recognition system for visually impaired/blind people
2. The project has the potential to develop a currency verification system.


![](https://i.imgur.com/Ea1LtVz.gif)
![](https://i.imgur.com/TIODbHY.gif)
![](https://i.imgur.com/r2Zi02f.gif)

### [Faster RCNN Model training for a custom COCO dataset ‚ö°](https://github.com/GirinChutia/FasterRCNN-Torchvision-FineTuning) 

This repository provides a user-friendly solution for training a Faster R-CNN model utilizing any custom COCO dataset. The Faster R-CNN algorithm is a widely used object detection framework known for its efficiency and accuracy in localizing and classifying objects within images. With this repository, one can seamlessly tailor the model to your specific needs. The primary focus of this repository is to streamline the process of training the Faster R-CNN model with any custom COCO dataset. 

## Publications

### [LW-ŒºDCNN: A Lightweight CNN Model for Human Activity Classification using Radar micro-Doppler Signatures](https://ieeexplore.ieee.org/document/10027123)

**Abstract:**
 
Recognition of human activities plays a pivotal role in recent times for surveillance and security. The convolution neural network (CNN) based models are growing to classify human activities using micro- Doppler (ŒºD) signatures. However, a larger number of parameters of the CNN models increases the computation cost and increases the size. The present work introduces a novel lightweight model, ‚ÄúLW ‚àíŒº DCNN,‚Äù to classify human activities. The architecture of LW ‚àíŒº DCNN has 438998 parameters with 7 layers. A total of six human activities are recorded in the FM CWR dataset, which is in the form of ŒºD signatures. These ŒºD signatures are converted into spectrogram images and are considered as input for the experiments. The size of the LW ‚àíŒº DCNN model is only 5.2 MB, which is further optimized by considering quantization aware training, ‚ÄúQAT-LW- Œº DCNN,‚Äù has size of 0.43 MB with minimal loss of accuracy. The extensive analysis shows that the LW ‚àíŒº DCNN model achieves 97% of classification accuracy with a higher F1-score for every class than the other state-of-the-art models. The present paper also proposed two transfer learning approaches, i.e., InceptionV3 and MobileNetV1, for the experimental studies to classify human activities.

---

![](https://komarev.com/ghpvc/?username=GirinChutia&label=PROFILE+VIEWS)


